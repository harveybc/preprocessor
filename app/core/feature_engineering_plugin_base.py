"""Feature Engineering Plugin Base Classes

This module provides abstract base classes for feature engineering plugins,
following the plugin interface specification from the design documentation.
"""

from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional, Tuple
import pandas as pd
import logging
from datetime import datetime


class FeatureEngineeringPlugin(ABC):
    """
    Abstract base class for feature engineering plugins.
    
    All feature engineering plugins must inherit from this class and implement
    the required methods according to the behavioral contracts specified in the
    unit-level design documentation.
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        Initialize the feature engineering plugin.
        
        Args:
            config: Plugin-specific configuration parameters
        """
        self.config = config or {}
        self.logger = logging.getLogger(f"{self.__class__.__module__}.{self.__class__.__name__}")
        self.metadata = self._generate_metadata()
        self.is_initialized = False
        self.processing_history = []
        
    @abstractmethod
    def get_plugin_info(self) -> Dict[str, Any]:
        """
        Get plugin information and metadata.
        
        Returns:
            Dictionary containing plugin information:
            - name: Plugin name
            - version: Plugin version
            - description: Plugin description
            - author: Plugin author
            - dependencies: List of plugin dependencies
            - input_requirements: Input data requirements
            - output_schema: Output data schema
        """
        pass
    
    @abstractmethod
    def validate_input(self, data: pd.DataFrame) -> Tuple[bool, List[str]]:
        """
        Validate input data meets plugin requirements.
        
        Args:
            data: Input DataFrame to validate
            
        Returns:
            Tuple of (is_valid, error_messages)
        """
        pass
    
    @abstractmethod
    def engineer_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        Engineer features from input data.
        
        Args:
            data: Input DataFrame
            
        Returns:
            DataFrame with engineered features added
            
        Behavior:
        - Process input data to generate new features
        - Preserve all original features unless explicitly configured otherwise
        - Handle missing data gracefully
        - Maintain temporal ordering if applicable
        """
        pass
    
    @abstractmethod
    def get_output_features(self) -> List[str]:
        """
        Get list of features that will be generated by this plugin.
        
        Returns:
            List of feature names that will be added to the dataset
        """
        pass
    
    def initialize(self, config: Optional[Dict[str, Any]] = None) -> bool:
        """
        Initialize the plugin with configuration.
        
        Args:
            config: Plugin configuration parameters
            
        Returns:
            True if initialization successful, False otherwise
        """
        try:
            if config:
                self.config.update(config)
            
            # Validate configuration
            validation_result = self._validate_configuration()
            if not validation_result[0]:
                self.logger.error(f"Configuration validation failed: {validation_result[1]}")
                return False
            
            # Perform plugin-specific initialization
            self._plugin_specific_initialization()
            
            self.is_initialized = True
            self.logger.info(f"Plugin {self.__class__.__name__} initialized successfully")
            return True
            
        except Exception as e:
            self.logger.error(f"Plugin initialization failed: {e}")
            self.is_initialized = False
            return False
    
    def cleanup(self) -> None:
        """
        Clean up plugin resources.
        
        Behavior:
        - Release any held resources
        - Clear temporary data
        - Reset plugin state if needed
        """
        try:
            self._plugin_specific_cleanup()
        except Exception as e:
            self.logger.error(f"Plugin cleanup failed: {e}")
        finally:
            # Always reset state regardless of cleanup success
            self.processing_history.clear()
            self.is_initialized = False
            self.logger.info(f"Plugin {self.__class__.__name__} cleaned up successfully")
    
    def process(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        Main processing method that orchestrates feature engineering.
        
        Args:
            data: Input DataFrame
            
        Returns:
            DataFrame with engineered features
            
        Raises:
            RuntimeError: If plugin is not initialized
            ValueError: If input validation fails
        """
        if not self.is_initialized:
            raise RuntimeError(f"Plugin {self.__class__.__name__} is not initialized")
        
        # Validate input
        is_valid, errors = self.validate_input(data)
        if not is_valid:
            raise ValueError(f"Input validation failed: {errors}")
        
        # Record processing start
        processing_start = datetime.now()
        
        try:
            # Engineer features
            result = self.engineer_features(data)
            
            # Validate output
            if not self._validate_output(data, result):
                raise ValueError("Output validation failed")
            
            # Record processing history
            self._record_processing(data, result, processing_start)
            
            self.logger.info(f"Feature engineering completed successfully")
            return result
            
        except Exception as e:
            self.logger.error(f"Feature engineering failed: {e}")
            raise
    
    def get_processing_history(self) -> List[Dict[str, Any]]:
        """
        Get processing history for this plugin.
        
        Returns:
            List of processing history entries
        """
        return self.processing_history.copy()
    
    def _generate_metadata(self) -> Dict[str, Any]:
        """Generate plugin metadata."""
        return {
            'class_name': self.__class__.__name__,
            'module': self.__class__.__module__,
            'created_at': datetime.now().isoformat(),
            'plugin_type': 'feature_engineering'
        }
    
    def _validate_configuration(self) -> Tuple[bool, List[str]]:
        """
        Validate plugin configuration.
        
        Returns:
            Tuple of (is_valid, error_messages)
        """
        # Default implementation - plugins can override
        return True, []
    
    def _plugin_specific_initialization(self) -> None:
        """Plugin-specific initialization logic."""
        # Default implementation - plugins can override
        pass
    
    def _plugin_specific_cleanup(self) -> None:
        """Plugin-specific cleanup logic."""
        # Default implementation - plugins can override
        pass
    
    def _validate_output(self, input_data: pd.DataFrame, output_data: pd.DataFrame) -> bool:
        """
        Validate output data.
        
        Args:
            input_data: Original input data
            output_data: Processed output data
            
        Returns:
            True if output is valid, False otherwise
        """
        try:
            # Check that output is a DataFrame
            if not isinstance(output_data, pd.DataFrame):
                self.logger.error("Output is not a pandas DataFrame")
                return False
            
            # Check that output has same or more columns
            if len(output_data.columns) < len(input_data.columns):
                self.logger.error("Output has fewer columns than input")
                return False
            
            # Check that output has same number of rows
            if len(output_data) != len(input_data):
                self.logger.error("Output has different number of rows than input")
                return False
            
            # Check that all original columns are preserved (unless configured otherwise)
            preserve_original = self.config.get('preserve_original_features', True)
            if preserve_original:
                missing_columns = set(input_data.columns) - set(output_data.columns)
                if missing_columns:
                    self.logger.error(f"Missing original columns in output: {missing_columns}")
                    return False
            
            return True
            
        except Exception as e:
            self.logger.error(f"Output validation error: {e}")
            return False
    
    def _record_processing(self, input_data: pd.DataFrame, output_data: pd.DataFrame, 
                          start_time: datetime) -> None:
        """Record processing history entry."""
        processing_time = (datetime.now() - start_time).total_seconds()
        
        history_entry = {
            'timestamp': start_time.isoformat(),
            'processing_time_seconds': processing_time,
            'input_shape': input_data.shape,
            'output_shape': output_data.shape,
            'features_added': len(output_data.columns) - len(input_data.columns),
            'new_features': list(set(output_data.columns) - set(input_data.columns)),
            'config_hash': hash(str(sorted(self.config.items())))
        }
        
        self.processing_history.append(history_entry)


class FeatureEngineeringPipeline:
    """
    Pipeline for executing multiple feature engineering plugins in sequence.
    """
    
    def __init__(self, plugins: Optional[List[FeatureEngineeringPlugin]] = None):
        """
        Initialize feature engineering pipeline.
        
        Args:
            plugins: List of feature engineering plugins
        """
        self.plugins = plugins or []
        self.logger = logging.getLogger(f"{self.__class__.__module__}.{self.__class__.__name__}")
        self.processing_history = []
    
    def add_plugin(self, plugin: FeatureEngineeringPlugin) -> None:
        """Add a plugin to the pipeline."""
        if not isinstance(plugin, FeatureEngineeringPlugin):
            raise TypeError("Plugin must inherit from FeatureEngineeringPlugin")
        
        self.plugins.append(plugin)
        self.logger.info(f"Added plugin {plugin.__class__.__name__} to pipeline")
    
    def process(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        Process data through the feature engineering pipeline.
        
        Args:
            data: Input DataFrame
            
        Returns:
            DataFrame with all engineered features
        """
        if not self.plugins:
            self.logger.warning("No plugins in pipeline, returning original data")
            return data.copy()
        
        result = data.copy()
        pipeline_start = datetime.now()
        plugin_results = []
        
        for i, plugin in enumerate(self.plugins):
            plugin_start = datetime.now()
            
            try:
                result = plugin.process(result)
                plugin_time = (datetime.now() - plugin_start).total_seconds()
                
                plugin_results.append({
                    'plugin_name': plugin.__class__.__name__,
                    'processing_time_seconds': plugin_time,
                    'features_added': len(result.columns) - (plugin_results[i-1]['total_features'] if i > 0 else len(data.columns)),
                    'total_features': len(result.columns),
                    'success': True
                })
                
                self.logger.info(f"Plugin {plugin.__class__.__name__} completed successfully")
                
            except Exception as e:
                self.logger.error(f"Plugin {plugin.__class__.__name__} failed: {e}")
                
                plugin_results.append({
                    'plugin_name': plugin.__class__.__name__,
                    'processing_time_seconds': (datetime.now() - plugin_start).total_seconds(),
                    'error': str(e),
                    'success': False
                })
                
                # Continue with next plugin
                continue
        
        # Record pipeline processing history
        pipeline_time = (datetime.now() - pipeline_start).total_seconds()
        
        history_entry = {
            'timestamp': pipeline_start.isoformat(),
            'total_processing_time_seconds': pipeline_time,
            'input_shape': data.shape,
            'output_shape': result.shape,
            'total_features_added': len(result.columns) - len(data.columns),
            'plugins_executed': len([r for r in plugin_results if r['success']]),
            'plugins_failed': len([r for r in plugin_results if not r['success']]),
            'plugin_results': plugin_results
        }
        
        self.processing_history.append(history_entry)
        
        self.logger.info(f"Pipeline processing completed: {len(result.columns) - len(data.columns)} features added")
        
        return result
    
    def get_pipeline_info(self) -> Dict[str, Any]:
        """Get information about the pipeline and its plugins."""
        return {
            'plugin_count': len(self.plugins),
            'plugins': [plugin.get_plugin_info() for plugin in self.plugins],
            'total_processing_runs': len(self.processing_history)
        }
    
    def initialize_plugins(self) -> bool:
        """Initialize all plugins in the pipeline."""
        success = True
        
        for plugin in self.plugins:
            if not plugin.initialize():
                self.logger.error(f"Failed to initialize plugin {plugin.__class__.__name__}")
                success = False
        
        return success
    
    def cleanup_plugins(self) -> None:
        """Clean up all plugins in the pipeline."""
        for plugin in self.plugins:
            try:
                plugin.cleanup()
            except Exception as e:
                self.logger.error(f"Failed to cleanup plugin {plugin.__class__.__name__}: {e}")
